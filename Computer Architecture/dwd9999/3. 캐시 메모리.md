# 캐시 메모리

CPU의 연산 속도는 메모리에 접근하는 시간보다 빠름  
이를 해결하기 위해 나온 것

**레지스터보다 용량이 크고 메모리보다 빠른** `SRAM` 기반 저장 장치  
<img src="https://github.com/user-attachments/assets/c452177c-3584-4f1c-864a-bfffd067b3a8" width="600" alt="이미지">

캐시 내에서도 비슷한 계층 구조를 가지고 있음  
코어와 가장 가까운 것이 `L1`, 다음으로 `L2`, `L3`  
`L1`과 `L2`는 각 코어가 가지고 있고, `L3`는 공유함  
<img src="https://github.com/user-attachments/assets/c0e4b8b0-3e21-460f-81a9-4c4bcc653abe" width="600" alt="이미지">

> **분리형 캐시**  
> 조금이라도 더 접근 속도를 빠르게 하기 위해 더 세분화 하기도 함  
> 명령어만을 저장하는 L1I  
> 데이터만을 저장하는 L1D

## 참조 지역성 원리

캐시 메모리는 용량이 작아 필요한 데이터를 예측해서 저장함  
예측이 맞아 캐시 메모리 내 데이터가 사용될 경우 `캐시 히트(Cache Hit)`라고 함  
반대로 예측이 틀리면 `캐시 미스(Cache Miss)`라고 함

> **캐시 적중률**  
> 캐시 히트 수 / (캐시 히트 수 + 캐시 미스 수)

캐시 적중률을 높이기 위해 **참조 지역성의 원리**에 따라 데이터를 가져옴

1. **시간 지역성**  
   변수에 값을 저장하면 언제든 다시 사용할 수 있음  
   즉, **최근 접근했던 메모리 공간을 다시 접근**하는 경우가 많음
2. **공간 지역성**  
   실행하려는 프로그램은 보통 관련 데이터들끼리 모여있음
   즉, **접근한 메모리 공간 근처를 접근**하는 경우가 많음